############################ input configuration sections
[T1]
path_to_search = /home/tom/phd/Dataset/All
filename_contains = T1
filename_not_contains = T1c,HGG,LGG,SABRE,Insight
spatial_window_size = (100, 100, 1)
axcodes=(L,P,S)
interp_order = 3

[T2]
path_to_search = /home/tom/phd/Dataset/All
filename_contains = T2
filename_not_contains = HGG,LGG,SABRE,Insight
spatial_window_size = (100, 100, 1)
axcodes=(L,P,S)
interp_order = 3

[Flair]
path_to_search = /home/tom/phd/Dataset/All
filename_contains = FLAIR
filename_not_contains = HGG,LGG,Flair,SABRE,Insight
spatial_window_size = (100, 100, 1)
axcodes=(L,P,S)
interp_order = 3

[label]
path_to_search = /home/tom/phd/Dataset/All
filename_contains = BinLesion
filename_not_contains = SABRE,Insight
spatial_window_size = (100, 100, 1)
axcodes=(L,P,S)
interp_order = 0

############################## system configuration sections
[SYSTEM]
cuda_devices = ""
num_threads = 20
num_gpus = 1
model_dir = /home/tom/phd/HeMIS_lesions/first_attempt
queue_length = 40

[NETWORK]
name = niftynet.contrib.hemis.hemis.HeMIS
activation_function = relu
decay = 1e-4
reg_type = L2
batch_size = 64
volume_padding_size=(0,0,0)
histogram_ref_file = /home/tom/phd/Dataset/lesion_mapping.txt
normalise_foreground_only = True
foreground_type = threshold_plus
multimod_foreground_type = and

[TRAINING]
optimiser = adam
sample_per_volume = 2
lr = 1e-3
loss_type = Dice
starting_iter = 0
save_every_n = 500
max_iter = 500000
max_checkpoints = 20
validation_every_n = 100
validation_max_iter = 22
exclude_fraction_for_validation = 0.1
tensorboard_every_n = 1

############################ custom configuration sections
[SEGMENTATION]
image = Flair,T1,T2
label = label
output_prob = False
num_classes = 2
label_normalisation = True

[EVALUATION]

[INFERENCE]
border = (0, 0, 0)
save_seg_dir = ./output/HeMIS
output_interp_order = 0
output_prob = False
spatial_window_size = (100, 100, 0)
