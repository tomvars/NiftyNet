############################ input configuration sections
[input]
csv_file = /home/tom/phd/Dataset/All_final_one_slice_without_ADNI_test_set_modality_classifier_hard/input.csv
;filename_contains = input
spatial_window_size = (100, 100, 1)
axcodes=(L,P,S)
interp_order = 3

[label]
csv_file = /home/tom/phd/Dataset/All_final_one_slice_without_ADNI_test_set_modality_classifier_hard/labels.csv
;filename_contains = label
spatial_window_size = (1, 1, 1)
interp_order = -1
axcodes=(A, R, S)

############################## system configuration sections
[SYSTEM]
cuda_devices = ""
num_threads = 1
num_gpus = 1
model_dir = /home/tom/phd/modality_classifier/final_hard
queue_length = 150
dataset_split_file = /home/tom/phd/Dataset/All_final_one_slice_without_ADNI_test_set_modality_classifier_hard/train_split.csv

[NETWORK]
name = niftynet.contrib.midl.resnet_plugin.ResNet
;name = niftynet.contrib.hemis_midl.toynetv2.ToyNet
;name = niftynet.network.resnet.ResNet
histogram_ref_file = /home/tom/phd/Dataset/mapping.txt
activation_function = relu
with_bn = True
decay = 1e-5
reg_type = L2
batch_size = 32
volume_padding_size=(0,0,0)
normalise_foreground_only = True
foreground_type = threshold_plus
multimod_foreground_type = and

[TRAINING]
optimiser = adam
sample_per_volume = 2
lr = 3e-4
loss_type = CrossEntropy
starting_iter = 0
save_every_n = 500
max_iter = 500000
max_checkpoints = 20
validation_every_n = 100
validation_max_iter = 22
exclude_fraction_for_validation = 0.1
tensorboard_every_n = 1

############################ custom configuration sections
[CLASSIFICATION]
image = input
label = label
output_prob = True
num_classes = 3
label_normalisation = True

[EVALUATION]

[INFERENCE]
border = (0, 0, 0)
save_seg_dir = ./output/modality_classifier
output_interp_order = 0
output_prob = False
spatial_window_size = (100, 100, 1)
